<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<title>Deep learning startup</title>
<link rel="stylesheet" type="text/css" href="https://rq-Chen.github.io/css/global.css">
<link rel="stylesheet" type="text/css" href="css/local.css"></head>
<body><div>
    <center>
    	<span style="float: left">
    		<a href="https://rq-chen.github.io/visualization-project/index.html">Before: Visualization project</a>
    	</span>
        <a href="https://rq-chen.github.io/index.html">Homepage</a>
    	<span style="float: right">
    		<a href="https://rq-chen.github.io/summer-school/index.html">Next: Summer school</a>
    	</span>
    </center>
</div>
<hr />
<h1 id='train-a-resnet20-v1-on-cifar10'>Train a ResNet20-v1 on CIFAR10</h1>
<p>&nbsp;</p>
<h2 id='introduction'>Introduction</h2>
<p>I try to implement a deep neural network on my laptop. Due to the weak computing capability (NVIDIA GTX 1060 3GB), I decided to train a relatively small network from scratch on a relatively small dataset. Therefore, I choosed <a href='https://towardsdatascience.com/resnets-for-cifar-10-e63e900524e0'>ResNet20-v1</a> and <a href='https://www.cs.toronto.edu/~kriz/cifar.html'>CIFAR10</a> dataset.</p>
<p><strong>My codes are available <a href='trainRes20.py'>here</a>, and the model weights are available <a href='saved_models/'>here</a>.</strong></p>
<p>ResNet is a famous convolutional neural network structure. It adopts identity/weighted shortcuts to facilitate the convergence of the model, which enables training super-deep neural networks (up to 1001 layers, much higher than the former models which only have no more than 20 layers). It&#39;s most characteristics structure is the residual block, where the arc arrow represents a shortcut connection:</p>
<p><img src = "https://upload.wikimedia.org/wikipedia/commons/thumb/5/5f/ResNets.svg/440px-ResNets.svg.png" style = "zoom:60%" /></p>
<p>The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. </p>
<p>I implement the model with <a href='https://keras.io/'>Keras</a> using <a href='https://www.tensorflow.org/'>Tensorflow 2</a> based on Python 3.7 (<a href='https://www.anaconda.com/'>Anaconda 3</a>) on Windows 10 (64bit). As a beginner, I referred to the <a href='https://keras.io/examples/cifar10_resnet/'>example code</a> provided by Keras. I understood and rewrite the code, but the structure and hyper-parameters are identical. I got hands-on experience with deep learning during this process, and became familiar with Keras model implementation and training.</p>
<p>&nbsp;</p>
<h2 id='environment'>Environment</h2>
<p>It is probably the most tiresome part:</p>
<ol start='' >
<li><p>Download and install <a href='https://www.anaconda.com/distribution/'>Anaconda 3</a> (using default settings).</p>
<p>Anaconda helps maintain Python packages and enables switching between different python version (e.g. python 2.7 and python 3.6) through virtual environments. In my case, I use python 3.7 as the default python, and create another environment for deep learning with <code>numpy</code>, <code>scipy</code>, <code>tensorflow</code>, <code>keras</code> and so on. Besides, I also installed Anaconda 2 (32bit) with python 2.7 (32bit) for other purpose. And there is no conflict among these different python environments up to now.</p>
</li>
<li><p>Add Anaconda directories to the system path:</p>
<ol start='' >
<li><code>C:\Users\YOURNAME\Anaconda3</code></li>
<li><code>C:\Users\YOURNAME\Anaconda3\Scripts</code></li>
<li><code>C:\Users\YOURNAME\Anaconda3\Library\bin</code></li>

</ol>
</li>
<li><p>Create a virtual environment for deep learning (optional):</p>
<p>Enter the command in cmd or Anaconda prompt (replace YOURENVNAME with the name your want, e.g. <code>tensorflow2py37</code>):</p>
<pre><code class='language-shell' lang='shell'>conda create -n YOURENVNAME
conda activate YOURENVNAME
</code></pre>
</li>
<li><p>Install tensorflow and relevant packages:</p>
<p>(If you&#39;re in China, probably you need to change the channel first in order to improve the download speed:</p>
<p><code>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/win-64/</code>)</p>
<p>Enter the command:</p>
<pre><code class='language-shell' lang='shell'>conda install tensorflow-gpu
</code></pre>
<p>And Anaconda will prepare everything for you.</p>
</li>
<li><p>Install other required packages:</p>
<p>View <a href='https://keras.io/#installation'>Keras installation guidance</a> to see if all dependencies are installed, if not, use <code>conda install xx</code> to install them.</p>
</li>
<li><p>Install Keras: <code>pip install keras</code>. You can deactivate the virtual environment now by <code>conda deactivate</code>.</p>
</li>
<li><p>Update the GPU driver with NVIDIA Geforce Experince.</p>
</li>
<li><p>Begin coding:</p>
<p>I launch <a href='https://code.visualstudio.com/'>Visual Studio Code</a> for programming in the Anaconda Navigator GUI, after choosing the python version (<strong>CAUTION: DON&#39;T OPEN VSCODE DIRECTLY OUTSIDE ANACONDA, otherwise the virtual environment won&#39;t work</strong>).</p>
</li>

</ol>
<p>&nbsp;</p>
<h2 id='coding'>Coding</h2>
<p>I rewrote the ResNet layer function to make it more concise:</p>
<pre><code class='language-python' lang='python'>def resLayer(_input, _filters = NBASEFILTERS, _kernelSize = 3, _stride = 1,
     _norm = True, _acti = True):
    &quot;&quot;&quot;A ResNet layer: Conv + BN + ReLu

    The last (3rd) layer in each block has no ReLu.
    Projection shortcut has no BN and no ReLu.
    &quot;&quot;&quot;
    x = _input
    x = Conv2D(_filters, kernel_size=_kernelSize, strides=_stride, padding=&#39;same&#39;,
        kernel_initializer=&#39;he_normal&#39;, kernel_regularizer=l2(L2WEIGHT))(x);
    if _norm:
        x = BatchNormalization()(x);
    if _acti:
        x = Activation(&#39;relu&#39;)(x);
    return x
</code></pre>
<p>And I extracted the residual block as a function for clearer model design:</p>
<pre><code class='language-python' lang='python'>def resBlock(_input, _stage, _block):
    &quot;&quot;&quot;resBlock - a residual block containing 2 conv and 1 shortcut

    &quot;&quot;&quot;
    nFilters = NBASEFILTERS * (2 ** _stage)
    if _stage &gt; 0 and _block == 0:  # downsample
        strides = 2
    else:
        strides = 1

    # 2 conv
    output = resLayer(_input, nFilters, _stride=strides)
    output = resLayer(output, nFilters, _acti=False)

    # shortcut
    if _stage &gt; 0 and _block == 0:  # projection
        # Caution: here the Keras document implementation differs from 
        #   the one mentioned before (in kernel size), and we use Keras&#39;s.
        _input = resLayer(_input, nFilters, _kernelSize=1,
            _stride=strides, _norm=False, _acti=False)

    output = keras.layers.add([_input, output])
    output = Activation(&#39;relu&#39;)(output)
    return output
</code></pre>
<p>The model generator:</p>
<pre><code class='language-python' lang='python'>def ResNet20(inputShape):
    &quot;&quot;&quot;ResNet20 - the network

    Returns a Keras model.
    &quot;&quot;&quot;
    inputs = Input(shape=inputShape)
    x = resLayer(inputs)  # resLayer1

    # resBlocks
    for nStage in range(3):
        for nBlock in range(3):
            x = resBlock(x, nStage, nBlock)

    x = AveragePooling2D(pool_size=8)(x)
    y = Flatten()(x)
    outputs = Dense(10, activation=&#39;softmax&#39;,
        kernel_initializer=&#39;he_normal&#39;)(y)

    # Generate model
    model = Model(inputs=inputs, outputs=outputs)
    return model
</code></pre>
<p>The training configuration was roughly the same as the Keras example, but I didn&#39;t use data augmentation.</p>
<p>&nbsp;</p>
<h2 id='result'>Result</h2>
<p>I trained for 50 epochs:</p>
<p><img src = "models_saved.png" style = "zoom:40%" /></p>
<p>The training loss was steadily decreasing, but it seems that the accuracy continued to fluctuate. The final loss and accuracy are roughly the same on tesing and training set. Even though it seems that the model was still under-fitting, it performed well (80% accuracy, much higher than chance level 10%) on the testing set (since I was not so familiar with Keras visualization, I use Matlab to plot).</p>
<p><img src = "TrainingProcess.png" style = "zoom:40%" /></p>
<p>A little problem is that the training process seems to be too slow (170 sec/epoch, while the benchmark on GTX 1080Ti (just 140% more powerful than my GPU, according to the <a href='https://gpu.userbenchmark.com/Compare/Nvidia-GTX-1080-Ti-vs-Nvidia-GTX-1060-3GB/3918vs3646'>UserBenchmark</a>) is 35 sec/epoch). Acoording to the terminal output, the GPU was correctly activated (<code>2019-12-03 02:48:20.844426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2103 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)</code>), but the GPU load is only around 20% during the training. Probably there are some other configurations to set in order to make full use of the GPU.</p>
<div>
    <center>
        <span style="float:left">
            <a href="/blogs.html">Blogs</a>
        </span>
        <a href="#top">Back to top</a>
    	<span style="float: right">
    		<a href="/index.html">Homepage</a>
    	</span>
    </center>
</div></body>
</html>